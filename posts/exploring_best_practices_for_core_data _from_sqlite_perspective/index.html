<!DOCTYPE html><html lang="zh"><head><meta charset="UTF-8"/><meta property="og:site_name" content="Ckitakishi"/><link rel="canonical" href="ckitakishi.com/posts/exploring_best_practices_for_core_data%20_from_sqlite_perspective"/><meta name="twitter:url" content="ckitakishi.com/posts/exploring_best_practices_for_core_data%20_from_sqlite_perspective"/><meta property="og:url" content="ckitakishi.com/posts/exploring_best_practices_for_core_data%20_from_sqlite_perspective"/><title>Exploring Best Practices for Core Data from SQLite Perspective | Ckitakishi</title><meta name="twitter:title" content="Exploring Best Practices for Core Data from SQLite Perspective | Ckitakishi"/><meta property="og:title" content="Exploring Best Practices for Core Data from SQLite Perspective | Ckitakishi"/><meta name="description" content="Exploring best practices for Core Data from a SQLite perspective can help us understand what's happening behind the scenes. This can be incredibly useful when creating high-performing, scalable, and reliable applications."/><meta name="twitter:description" content="Exploring best practices for Core Data from a SQLite perspective can help us understand what's happening behind the scenes. This can be incredibly useful when creating high-performing, scalable, and reliable applications."/><meta property="og:description" content="Exploring best practices for Core Data from a SQLite perspective can help us understand what's happening behind the scenes. This can be incredibly useful when creating high-performing, scalable, and reliable applications."/><meta name="twitter:card" content="summary"/><link rel="stylesheet" href="/styles.css" type="text/css"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"/><link rel="alternate" href="/feed.rss" type="application/rss+xml" title="Subscribe to Ckitakishi"/><!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-107870195-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'UA-107870195-1');
</script></head><body><div class="flex flex-col min-h-full text-zinc-900 dark:text-zinc-50"><div class="grid grid-cols-8 w-full h-[8px]"><div class="bg-[#ab4642]"></div><div class="bg-[#dc9656]"></div><div class="bg-[#f7ca88]"></div><div class="bg-[#a1b56c]"></div><div class="bg-[#86c1b9]"></div><div class="bg-[#7cafc2]"></div><div class="bg-[#ba8baf]"></div><div class="bg-[#a16946]"></div></div><header class="flex justify-center p-4 text-zinc-900 dark:text-zinc-50"><div class="flex flex-wrap justify-between my-4 gap-x-16 max-w-screen-lg w-full"><a href="/" class="header-title font-extrabold text-3xl">Ckitakishi</a><nav class="my-auto"><ul class="flex flex-wrap gap-4"><li><a href="/" class="hover:underline underline-offset-4">Home</a></li><li><a href="/posts" class="hover:underline underline-offset-4">Writing</a></li><li><a href="/tags/求索集/" class="hover:underline underline-offset-4">求索集</a></li><li><a href="/tags/浮生记/" class="hover:underline underline-offset-4">浮生记</a></li><li><a href="https://photo.ckitakishi.com" class="hover:underline underline-offset-4">Photo</a></li><li><a href="/feed.rss" class="hover:underline underline-offset-4">RSS</a></li></ul></nav></div></header><div class="flex justify-center mx-4"><div class="max-w-screen-md w-full m-4"><div class="flex text-zinc-600 dark:text-zinc-50 mb-1"><p class="flex shrink-0">May 7, 2025</p><p class="mx-3 text-lg -mt-0.5">|</p><ul class="flex flex-wrap gap-2"><li><a href="/tags/求索集" class="hashtag link-underline">求索集</a></li><li><a href="/tags/ios" class="hashtag link-underline">iOS</a></li><li><a href="/tags/core-data" class="hashtag link-underline">Core Data</a></li></ul></div><article class="prose prose-zinc min-w-full dark:prose-invert"><div class="content"><h1>Exploring Best Practices for Core Data from SQLite Perspective</h1><p>This article was originally published at:</p><blockquote><p><a href="https://techblog.lycorp.co.jp/en/exploring-best-practices-for-core-data-from-the-sqlite-perspective">https://techblog.lycorp.co.jp/en/exploring-best-practices-for-core-data-from-the-sqlite-perspective</a></p></blockquote><h2>Introduction</h2><p>The application I'm currently working on uses Core Data for local data persistence. Core Data provides four store types by default: SQLite, Binary, XML, and In-Memory (the XML store is not available on iOS). Throughout the development process, we've gained valuable experience about using Core Data correctly and efficiently, especially from the SQLite perspective.</p><p>If you're using Core Data and want to learn more about how to maximize the underlying SQLite database, this post is for you.</p><h2>1. Properly storing BLOB</h2><h3>1.1 SQLite Team's perspective</h3><p>When I first started learning about relational databases, I wondered whether the BLOB (Binary Large OBject) should be stored in the database, as an external file, or in a hybrid way? This is a common question, and the SQLite documentation provides two insightful discussions on this topic: <a href="https://www.sqlite.org/intern-v-extern-blob.html">Internal Versus External BLOBs in SQLite</a> and <a href="https://www.sqlite.org/fasterthanfs.html">35% Faster Than The Filesystem</a>.</p><p>What surprised me the most is the following comparison：</p><blockquote><p>SQLite reads and writes small blobs (for example, thumbnail images) 35% faster than the same blobs can be read from or written to individual files on disk using fread() or fwrite(). Furthermore, a single SQLite database holding 10-kilobyte blobs uses about 20% less disk space than storing the blobs in individual files.</p></blockquote><p>Additionally, the SQLite team shared an interesting benchmark result of BLOBs' reading performance with different page sizes (Just for your information: the default page size of SQLite used in Core Data is 4096).</p><blockquote><p>The matrix below shows the time needed to read BLOBs stored in separate files divided by the time needed to read BLOBs stored entirely in the database</p></blockquote><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/1-1.png" alt="1-1"/><p>In their test environments, storing BLOBs up to 20k always have better reading performance, on the other hand, for the BLOBs over 200k, storing them as external files would be more efficient.</p><p>While these benchmark results may not be directly applicable to us, we can still glean some important insights from them:</p><ul><li>As a rule of thumb, it's wise to store small BLOBs in the database and large BLOBs as external files.aking, it's wise to store small BLOBs in the database and large BLOBs as external files.</li><li>When it's difficult to choose between internal and external storage, conducting a benchmark could be helpful.</li></ul><h3>1.2 Returning to our Core Data world</h3><p>Now, let's apply our SQLite knowledge to the world of Core Data!</p><p>You may already be familiar with a property called <code>allowsExternalBinaryDataStorage</code>, which can be used to let Core Data decide how to store binary objects. When the BLOBs are stored as external files, they're placed in a hidden subdirectory within the same directory as the database files. In the database fields, only the filenames (UUID) corresponding to the external files are stored.</p><pre><code><span class="type">Database</span>/
├─ {sqlite-file-name}<span class="type">_SUPPORT</span>/
│  ├─ <span class="type">_EXTERNAL_DATA</span>/
│  │  ├─ file1
│  │  ├─ file2
├─ {sqlite-file-name}.sqlite
├─ {sqlite-file-name}.wal
├─ {sqlite-file-name}.shm
</code></pre><p>Obviously, the Core Data team provides a way for us to avoid making this difficult decision.</p><p>I have roughly tested <code>allowsExternalBinaryDataStorage</code> on an iOS 16.4 simulator. Based on my tests, the data size threshold for determining how to store binary objects is between 100k~150k. Changing the number of attributes and rows didn't affect the result. However, please note that this is just a reference. I believe the Core Data team conducted a lot of benchmark tests to define a "large object". In general, considering binary objects smaller than 100k as small seems reasonable.</p><p>Now we have three options to manage our binary objects:</p><ol><li>Store them in the database.</li><li>Store them as external files.</li><li>Enable <code>allowsExternalBinaryDataStorage</code> or implement a custom hybrid approach.</li></ol><p>Another thing to consider is that when your tables are small, even if you store very large BLOBs in the database, the performance degradation is subtle and negligible. However, if a table has a large number of attributes and rows, storing small binary objects may significantly worsen the performance. In this case, storing small objects in the database may not be a good idea anymore.</p><p>In conclusion, there's no absolute best answer. We should make a decision based on the specific use case and consider the trade-offs between performance, storage, and convenience.</p><h2>2. Copying the underlying SQLite database</h2><p>Copying a SQLite database is not as simple as it seems. Especially after Apple changed the default journal mode for Core Data SQLite stores to <a href="https://www.sqlite.org/wal.html">Write-Ahead Logging (WAL)</a> in iOS 7 and OS X Mavericks 10.9. Compared with the original default journal mode <code>DELETE</code>, two temporary files are added. Simply put, the <code>.wal</code> file can be considered as a transactions container, where all changes are eventually transferred back into the original <code>.sqlite</code> file when a checkpoint operation is triggered. The <code>.shm</code> file is used as part of the mechanism that allows multiple database connections to SQLite databases.</p><p>When attempting to copy a SQLite database that uses the default <code>WAL</code> mode, a common mistake is only copying the <code>.sqlite</code> file. As you can guess, the result is that transactions that were previously committed to the database might be lost. Even worse, the database file could become corrupted.</p><p>Therefore, using reliable methods to copy SQLite databases is very important. Fortunately, the following solutions should help:</p><h3>2.1 Using the Backup API provided by Core Data</h3><p><code>migratePersistentStore(_:to:options:type:)</code> is a powerful and straightforward API. Remember the <code>allowsExternalBinaryDataStorage</code> we discussed in previous section? If this value is set to <code>true</code>, BLOBs may be stored as external files on disk. The good news is this method takes the responsibility of copying the external files during the migration as well.</p><p>However, as mentioned in <a href="https://oleb.net/blog/2018/03/core-data-sqlite-backup/">this wonderful article</a>, the data copying is actually reading stored data into memory and then storing them to the new database (no changes on latest OSes). So, you have to ensure that your application won't stop working due to memory overload during the data copying.</p><pre><code><span class="keyword">func</span> migratePersistentStore(
    <span class="keyword">_</span> store: <span class="type">NSPersistentStore</span>,
    to storeURL: <span class="type">URL</span>,
    options: [<span class="type">AnyHashable</span> : <span class="type">Any</span>]? = <span class="keyword">nil</span>,
    type storeType: <span class="type">NSPersistentStore</span>.<span class="type">StoreType</span>
) <span class="keyword">throws</span> -&gt; <span class="type">NSPersistentStore</span>
</code></pre><p>Another point that makes me think this API can be further improved is that, as far as I know, there's no built-in mechanism to track the progress of data copying. This can be troublesome, especially when dealing with large databases or time-consuming operations.</p><p>Although the API has room for improvement, I believe it should still be your first choice in most cases.</p><h3>2.2 Using SQLite approaches to backup</h3><p>If you want more control over the copying process, using SQLite's methods to copy files is also an option. There are mainly two ways to achieve your goal, but keep in mind that you will need to handle other parts besides SQLite files yourself, such as external files created by Core Data.</p><h4>2.2.1 SQLite Online Backup API</h4><p>As mentioned in the SQLite documentation, the <a href="https://www.sqlite.org/c3ref/backup_finish.html#sqlite3backupinit">Online Backup API</a> was created to address the concerns that arise from copying SQLite files with external tools like the file system. Since <code>SQLite3</code> can be imported on iOS by default, we can easily perform the copy operation like the following:</p><pre><code><span class="comment">/// Copies the content of one database into another.
///
/// - Parameters:
///   - pageCount: The page count to copy in each step. If the count is negative, all remaining source pages are copied.
///   - progress: A closure can be used to track the progress of the copy.</span>
<span class="keyword">func</span> backup(pageCount: <span class="type">Int32</span> = -<span class="number">1</span>，progress: ((<span class="type">Int</span>, <span class="type">Int</span>) -&gt; <span class="type">Void</span>)? = <span class="keyword">nil</span>) {
    <span class="keyword">var</span> statusCode = <span class="comment">// ...

    // Initialize backup</span>
    <span class="keyword">guard let</span> backup = <span class="call">sqlite3_backup_init</span>(sourceDatabase, <span class="string">"main"</span>, destinationDatabase, <span class="string">"main"</span>) <span class="keyword">else</span> {
        <span class="comment">// Handle the error</span>
    }

    <span class="keyword">repeat</span> {
        <span class="comment">// Transfer the data between two databases</span>
        statusCode = <span class="call">sqlite3_backup_step</span>(backup, pageCount)
        progress?(<span class="call">sqlite3_backup_remaining</span>(backup), <span class="call">sqlite3_backup_pagecount</span>(backup))
        <span class="keyword">if</span> statusCode == <span class="type">SQLITE_BUSY</span> || statusCode == <span class="type">SQLITE_LOCKED</span> {
            <span class="call">sqlite3_sleep</span>(<span class="number">250</span>)
        }
    } <span class="keyword">while</span> statusCode == <span class="type">SQLITE_OK</span> || statusCode == <span class="type">SQLITE_BUSY</span> || statusCode == <span class="type">SQLITE_LOCKED</span>

    <span class="comment">// Release all resources</span>
    statusCode = <span class="call">sqlite3_backup_finish</span>(backup)
}
</code></pre><h4>2.2.2 The <code>VACUUM INTO</code> command</h4><p>In SQLite, you use the <code>VACUUM</code> command to optimize and reduce the size of the database file.</p><p>Starting with SQLite version 3.27.0 (released on 2019-02-07), the <code>INTO</code> clause was introduced. With <code>INTO</code>, the original database file remains unchanged, and a new database is created in a file named by the argument to the <code>INTO</code> clause. When comparing this to the backup API, SQLite explains:</p><blockquote><p>The advantage of using <code>VACUUM INTO</code> is that the resulting backup database is minimal in size and hence the amount of filesystem I/O may be reduced. Also, all deleted content is purged from the backup, leaving behind no forensic traces. On the other hand, the backup API uses fewer CPU cycles and can be executed incrementally.</p></blockquote><pre><code><span class="keyword">var</span> statusCode = <span class="comment">// ...
// Execute the VACUUM INTO command to create a new compacted database</span>
statusCode = <span class="call">sqlite3_exec</span>(database, <span class="string">"VACUUM INTO</span> \(destinationURL)<span class="string">"</span>, <span class="keyword">nil</span>, <span class="keyword">nil</span>, <span class="keyword">nil</span>)
</code></pre><h3>2.3 Did I forget anything?</h3><p>Finally, let's talk about why it's best to avoid copying files with File System APIs as much as possible, unless you're sure about what you're doing and are confident in your decision.</p><p>Consider this scenario: you start copying files while a transaction is in progress. What could go wrong? There's a real risk of creating data inconsistency, which could corrupt the new database.</p><p>Although we could prevent this problem by making sure no other connections are modifying the original database, this method is still risky. Furthermore, copying only files with certain extensions could weaken your code. We can't predict if a new journal mode will be introduced in the future, possibly bringing new files with different extensions.</p><p>To lessen these risks, I suggest using suitable database-specific APIs to manage the complexities of copying databases.</p><h2>3. Designing indexes</h2><p>In our everyday development work, we frequently use indexes to speed up searches in Core Data. It's true that indexes can sometimes greatly enhance search and sort performance.</p><p>However, there's one thing you shouldn't ignore: adding indexes incurs a cost. First, because indexes are stored in a separate table, the size of the database file increases. Second, operations like inserting, updating, and deleting become more costly. This is due to the fact that not only does the data in the original table need to be updated, but the data in the index table also needs to be modified. If you don't use indexes correctly, it could lead to poorer performance, despite having more indexes.</p><p>Therefore, it's vital to understand how indexes function. This knowledge will help you make informed decisions about when and where to use indexes.</p><h3>3.1 How can an index improve search performance?</h3><p>Before we start, I must admit that the <a href="https://www.sqlite.org/queryplanner.html#_sorting_by_covering_index">SQLite document</a> was a great help in understanding the mechanism of indexing. The following content in this section is all based on this document.</p><p>Let's say we have an entity called <code>FruitForSale</code>. There are three attributes defined on <code>FruitForSale</code>: <code>fruit</code>, <code>state</code> and <code>price</code>.</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-1.png" alt="3-1"/><h4>3.1.1 Table without an index</h4><p>When you run the following fetch request without an index, a <strong>full table scan</strong> will take place. The database will scan the rows one by one until it finds the desired item, in this case, the "Peach". The performance of a full table scan heavily depends on the amount of data. As the data volume increases, the search can become significantly slower.</p><pre><code><span class="keyword">let</span> fetchRequest = <span class="type">FruitForSale</span>.<span class="call">fetchRequest</span>()
fetchRequest.<span class="property">predicate</span> = <span class="type">NSPredicate</span>(format: <span class="string">"fruit == %@"</span>, <span class="string">"Peach"</span>)
</code></pre><h4>3.1.2 Adding a single-column index</h4><p>In the latest Xcode version (15.0 Beta), we can easily add indexes using the Model Editor, as shown below:</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-2.png" alt="3-2"/><p>After adding an index on the <code>fruit</code> attribute, a corresponding index table is created behind the scenes. This index table contains a <code>fruit</code> column with the same contents as the original table, but sorted in a specific order, followed by an id column.</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-3.png" alt="3-3"/><p>Under the hood, SQLite uses B-trees to store indexes, which allows for efficient searches using binary search. This is a significant improvement over linear search, which has a time complexity of O(N). Binary search, on the other hand, offers significantly better performance with a time complexity of O(log N). As the amount of data increases, this performance difference becomes more noticeable.</p><p>There's another performance improvement to note. For instance, when searching for "Orange" in SQLite, instead of performing two separate binary searches, SQLite optimizes the process by advancing to the next row of the index after the first binary search is completed, to repeat the search for the next <code>fruit = "Orange"</code>. This operation is much less costly than performing a binary search each time.</p><h4>3.1.3 Adding multi-column indexes</h4><p>Let's consider another scenario. Say we modify our fetch request to find all oranges grown in California:</p><pre><code><span class="keyword">let</span> fetchRequest = <span class="type">FruitForSale</span>.<span class="call">fetchRequest</span>()
fetchRequest.<span class="property">predicate</span> = <span class="type">NSPredicate</span>(format: <span class="string">"fruit == %@ AND state == %@"</span>, <span class="string">"Orange"</span>, <span class="string">"CA"</span>)
</code></pre><p>In this situation, we have two potential solutions. I'll illustrate the differences using code that programmatically creates the indexes. This approach might be easier to understand than using the Model Editor:</p><pre><code><span class="comment">// Solution 1: Mutiple Single-Column Indexes</span>
indexes = [
    .<span class="keyword">init</span>(name: <span class="string">"byFruitIndex"</span>, elements: [.<span class="keyword">init</span>(property: fruit, collationType: .<span class="dotAccess">binary</span>)])
    .<span class="keyword">init</span>(name: <span class="string">"byStateIndex"</span>, elements: [.<span class="keyword">init</span>(property: state, collationType: .<span class="dotAccess">binary</span>)])
]

<span class="comment">// Solution 2: Multi-Column Index</span>
indexes = [
    .<span class="keyword">init</span>(
        name: <span class="string">"byFruitAndStateIndex"</span>,
        elements: [
            .<span class="keyword">init</span>(property: fruit, collationType: .<span class="dotAccess">binary</span>),
            .<span class="keyword">init</span>(property: state, collationType: .<span class="dotAccess">binary</span>)
        ]
    )
]
</code></pre><ol><li>In the first solution, two index tables will be created: one for the <code>fruit</code> column and another for the <code>state</code> column. Since only one index can be used in a single lookup, SQLite will internally decide which index to use (there are some rules governing this, but I won't delve into them here). In this case, regardless of which index is used, the time required is the same. Both indexes will perform a binary search three times: once in the index table and twice in the data table.</li></ol><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-4.png" alt="3-4"/><ol start="2"><li>In the second solution, only one index table is created. Clearly, in this scenario, it will have better search performance than the first solution. Here, only two binary searches are needed: once in the index table and once in the data table.</li></ol><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-5.png" alt="3-5"/><p>In conclusion, both solutions can enhance lookup performance. However, note that applying both solutions simultaneously will only result in wasted space without providing any additional performance benefits.</p><h3>3.2 Sorting</h3><p>Having understood searching, you'll find that sorting isn't much different. Consider a fetch request that retrieves all items sorted by the <code>fruit</code> attribute:</p><pre><code><span class="keyword">let</span> fetchRequest = <span class="type">FruitForSale</span>.<span class="call">fetchRequest</span>()
fetchRequest.<span class="property">sortDescriptors</span> = [<span class="type">NSSortDescriptor</span>(key: <span class="string">"fruit"</span>, ascending: <span class="keyword">true</span>)]
</code></pre><h4>3.2.1 Adding a single-column index</h4><p>In this scenario, even if the <code>fruit</code> column is sorted, SQLite would need to perform multiple binary searches to fetch the data for the <code>state</code> and <code>price</code> columns. This results in a time complexity of O (Nlog N).</p><p>The performance isn't bad, but it's quite similar to some sorting algorithms, right? Let's consider a situation where there is no index. In this case, SQLite uses a sorting algorithm called "internal merge sort", which also has a time complexity of around O (Nlog N).</p><p>Therefore, in my opinion, if this index is created solely for sorting purposes, it might not be the best idea. However, if you're already using the index for searching, it could provide some benefits, as mentioned in the SQLite documentation:</p><blockquote><p>Generally speaking, the indexed sort would probably be chosen, if for no other reason, because it does not need to accumulate the entire result set in temporary storage before sorting and thus uses much less temporary storage.</p></blockquote><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-6.png" alt="3-6"/><h4>3.2.2. Adding a covering index</h4><p>In some cases, if a covering index can be used for sorting, it can help avoid multiple binary searches and significantly improve performance. A covering index is an index that includes all the columns needed for a specific query or operation.</p><p>However, it's important to weigh whether the performance improvement is worth the trade-off of doubling the size of the database.</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/3-7.png" alt="3-7"/><h3>3.3 Experience and tips</h3><p>Based on the discussion above, I strongly suggest keeping the following tips in mind when working with indexes:</p><ul><li>Consider the size of your data: If you're dealing with a small amount of data, an index might not be very helpful.</li><li>Find the balance: If your application primarily focuses on insertions, updates, and deletion operations rather than searching, adding indexes might not be the best approach.</li><li>Avoid misuse of indexes: For example, the same attributes shouldn't be used as primary keys in multiple index tables.</li><li>Benchmark and analyze: It's highly recommended to perform benchmarking and analysis before and after optimizing your database, especially if you're unsure about the potential benefits (related content will be covered in the "Debugging SQLite in Core Data" section).</li></ul><h2>4. Using predicates wisely</h2><p>Using <code>NSPredicate</code> with Core Data allows us to perform efficient queries on SQLite stores, making it easier to fetch objects that meet specific criteria. However, this also results in some details being hidden beneath the surface implementation when using predicates.</p><p>In this section, we won't be able to cover everything related to predicates, but I hope to share some ways to understand how SQLite works behind the scenes with predicates by exploring a few questions.</p><h3>4.1 Using <code>BEGINSWITH</code> instead of <code>CONTAINS</code> when possible</h3><p>Let's consider the following example: if there are some titles stored in the database, and we want to fetch all strings that begin with "_", what kind of predicate are you going to use?</p><pre><code><span class="comment">// Data</span>
<span class="keyword">let</span> titles = [<span class="string">"_a"</span>, <span class="string">"_b"</span>, <span class="string">"c"</span>, <span class="string">"_d"</span>, <span class="string">"e"</span>]

<span class="comment">// BEGINSWITH</span>
<span class="type">NSPredicate</span>(format: <span class="string">"title BEGINSWITH %@"</span>, <span class="string">"_"</span>)

<span class="comment">// CONTAINS</span>
<span class="type">NSPredicate</span>(format: <span class="string">"title CONTAINS %@"</span>, <span class="string">"_"</span>)
</code></pre><p>In this case, both <code>BEGINSWITH</code> and <code>CONTAINS</code> can help you achieve your goal. However, when the dataset is large and the <code>title</code> column has a valid index, <code>BEGINSWITH</code> performs much better than <code>CONTAINS</code>. The reason for this is that even if an index exists on the <code>title</code> column, SQLite still needs to scan the whole table to check all of the data to find records containing _. But with <code>BEGINSWITH</code>, all titles that begin with <code>_</code> are in consecutive rows, which obviously results in better performance.</p><p>Not only <code>CONTAINS</code>, but also <code>ENDSWITH</code>, <code>LIKE</code>, and some other operators can't benefit from the index for the same reason.</p><h3>4.2 <code>BEGINSWITH[cd]</code> may not perform as well as we expect</h3><p>When using the <code>BEGINSWITH[cd]</code> operator, which is case (c) and diacritic (d) insensitive, the performance may not be as good as we might expect. Let's assume we have the following data stored in the database:</p><pre><code><span class="keyword">let</span> titles = [<span class="string">"abc"</span>, <span class="string">"ABC"</span>, <span class="string">"Abc"</span>, <span class="string">"ábć"</span>, <span class="string">"Ábc"</span>]
</code></pre><p>If we want to fetch all titles that begin with "ab", ignoring case and diacritics, we can use the <code>BEGINSWITH[cd]</code> operator in our predicate:</p><pre><code><span class="type">NSPredicate</span>(format: <span class="string">"title BEGINSWITH[cd] %@"</span>, <span class="string">"ab"</span>)
</code></pre><p>Earlier, I mentioned that <code>BEGINSWITH</code> performs relatively well. You might be wondering why <code>BEGINSWITH[cd]</code> performs so differently?</p><p>SQLite <a href="https://www.sqlite.org/draft/datatype3.html#collating_sequences.">compares string data byte-by-byte with <code>memcmp()</code></a>, which means it's case and diacritic sensitive by default. As SQLite doesn't even support diacritic insensitive lookup, the functionality to perform case and diacritic insensitive searches is provided by Core Data. Therefore, data needs to be fetched into memory for comparison, which could impact performance.</p><p>While it's true that not knowing the underlying implementation can sometimes lead to misuse and overuse, these features provided by Core Data are still incredibly valuable and helpful.</p><p>My take on this is that we should enjoy the power that Core Data provides. If it does have a serious impact on performance, we could find some solution to mitigate the problem, such as storing <a href="https://www.unicode.org/reports/tr15/">normalized strings</a> in a new column for quicker searches.</p><h3>4.3 Aggregate operations</h3><p>There are several available aggregate operations that can be used in Core Data: <code>@avg</code>, <code>@count</code>, <code>@sum</code>, <code>@max</code> and <code>@min</code>. They can be very useful.</p><p>Let's consider a case with two entities: <code>Department</code> and <code>Employee</code>. The <code>Department</code> entity has a one-to-many relationship called <code>employees</code> to represent all the employees in that department. Now, suppose we want to calculate the average salary of employees in a specific department.</p><p>Using the <code>@avg</code> operator, we can write the predicate as follows:</p><pre><code><span class="keyword">let</span> departmentName = <span class="string">"Development"</span>
<span class="keyword">let</span> predicate = <span class="type">NSPredicate</span>(format: <span class="string">"name == %@.@avg.employees.salary"</span>, departmentName)
</code></pre><p>In the above case, the <code>@avg</code> operator is very useful, but it's not a low-cost operation, and Core Data doesn't cache the results of calculations. So, when we're working with a large dataset and the need for searching is much greater than updating, it's worth considering calculating the average salary and storing it in the database.</p><h3>4.4 Compound predicate</h3><p>If you're familiar with basic predicates, using compound predicates will be a breeze. The most important points you need to remember are:</p><ul><li>Try to narrow the search results dataset as much as possible.</li><li>Perform the efficient predicate first.</li></ul><p>Suppose we have a very large book information table where most books cost less than 5,000 yen, and company Z is the largest publisher, holding over 80% of the market.</p><table><thead><tr><th>title</th><th>price</th><th>publisher</th></tr></thead><tbody><tr><td>abc</td><td>8800</td><td>Z</td></tr><tr><td>ABC</td><td>2200</td><td>X</td></tr><tr><td>ábć</td><td>3000</td><td>Y</td></tr><tr><td>def</td><td>3500</td><td>Z</td></tr></tbody></table><p>When we want to find all books that cost more than 5,000 yen and are published by company Z, the following predicate is relatively the most efficient. This is because the most expensive condition (<code>BEGINSWITH[cd]</code>) is placed last, and <code>price &gt; 5000</code> narrows down the search scope more than <code>publisher == "Z"</code>.</p><pre><code><span class="keyword">let</span> predicate = <span class="type">NSPredicate</span>(format: <span class="string">"price &gt; %@ AND publisher == %@ AND title BEGINSWITH[cd] %@"</span>, <span class="number">5000</span>, <span class="string">"Z"</span>, <span class="string">"ab"</span>)
</code></pre><p>Optimizing a single predicate may only have a negligible impact, however, it's definitely worth trying to use more predicates wisely.</p><h2>5. Subentities may not always be the ideal choice</h2><h3>5.1 Pros and cons of subentities</h3><p>Core Data uses a strategy called "single table inheritance" (STI) to store subentities. This means all of the subentities and their superentity are stored in a single table. For example:</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/5-1.png" alt="5-1"/><p>As shown in the diagram above, in the end, only one table is created, and all attributes of <code>Image</code> and <code>Video</code> are stored in the <code>Media</code> table. The pros and cons of using STI in Core Data are very clear:</p><p><strong>Pros:</strong></p><ul><li>Good fetch performance: It's possible to fetch all subentities with a single fetch request: <code></code>`swift let fetchRequest = Entity.fetchRequest() fetchRequestA.includesSubentities = true // Default is true <code></code>`</li><li>Simplicity: When subentities have very few different attributes, STI is straightforward enough.</li></ul><p><strong>Cons:</strong></p><ul><li>Limited scalability: As the number of entities or attributes grows, performance can be heavily impacted due to the increased size and complexity of the table.</li><li>Space waste: When subentities have a large number of different attributes, there will be a lot of <code>null</code> fields in the database, which can be considered as a waste of storage space.</li></ul><p>After understanding the pros and cons, we can choose to use subentities or not depending on the specific scenario.</p><h3>5.2 Alternative approach</h3><p>If your actual use case doesn't fit the use of subentities, but you still want to create a parent-child relationship between entities, a good solution would be to keep the entities defined in the data model separate and use inheritance on <code>NSManagedObject</code> classes instead.</p><pre><code><span class="comment">// Generated by Xcode</span>
<span class="keyword">@objc</span>(<span class="type">Media</span>)
<span class="keyword">public class</span> Media: <span class="type">NSManagedObject</span> {}

<span class="keyword">extension</span> <span class="type">Media</span> {
    <span class="keyword">@nonobjc public class func</span> fetchRequest() -&gt; <span class="type">NSFetchRequest</span>&lt;<span class="type">Media</span>&gt; {
        <span class="keyword">return</span> <span class="type">NSFetchRequest</span>&lt;<span class="type">Media</span>&gt;(entityName: <span class="string">"Media"</span>)
    }
    <span class="keyword">@NSManaged public var</span> title: <span class="type">String</span>?
}

<span class="comment">// Make Image inherit from Media manually</span>
<span class="keyword">@objc</span>(<span class="type">Image</span>)
<span class="keyword">public class</span> Image: <span class="type">Media</span> {}

<span class="keyword">extension</span> <span class="type">Image</span> {
    <span class="keyword">@nonobjc public class func</span> fetchRequest() -&gt; <span class="type">NSFetchRequest</span>&lt;<span class="type">Image</span>&gt; {
        <span class="keyword">return</span> <span class="type">NSFetchRequest</span>&lt;<span class="type">Image</span>&gt;(entityName: <span class="string">"Image"</span>)
    }
    <span class="keyword">@NSManaged public var</span> alphaChannel: <span class="type">Bool</span>
}
</code></pre><h2>6. Debugging SQLite in Core Data</h2><p>If you ask me which part of this post is the most useful, I'd probably say this section! This is because understanding how to analyze the use of SQLite in Core Data can bring numerous benefits, such as:</p><ul><li>Gaining a deeper understanding of how data is stored and retrieved.</li><li>Determining whether performance needs to be optimized based on the data.</li><li>Gaining useful information when investigating complex Core Data-related issues.</li></ul><p>There are a lot of useful tools provided by Core Data itself and Instruments.</p><h3>6.1 Using launch arguments</h3><p>For most Core Data users, the launch argument <code>SQLDebug</code> may already be a familiar tool, but today I want to dig a little deeper into its usage.</p><pre><code>-com.<span class="property">apple</span>.<span class="type">CoreData</span>.<span class="type">SQLDebug</span> &lt;log-level&gt; <span class="comment">// supported values: 1/2/3/4</span>
</code></pre><p><code>SQLDebug</code> offers four log levels. The higher the log level, the more detailed the logs you'll receive. Once you've enabled <code>SQLDebug</code>, logs similar to the ones below will be printed based on the log level:</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/6-1.png" alt="6-1"/><ul><li>For log level 1 and above, you'll see:<ul><li>SQL statements executed by SQLite</li><li>Fetch time (Note: Core Data doesn't display save time.)</li><li>For log level 2 and above, you'll see:</li><li>Parameter values set using the <code>sqlite3_bind_*()</code> method</li><li>Entity name</li><li>For log level 3 and above, you'll see:</li><li>Returned values</li><li>For log level 4 and above, you'll see:</li><li>The result of the <code>EXPLAIN QUERY PLAN</code> command</li></ul></li></ul><p>In most situations, setting the log level to 3 is sufficient. It lets you review SQL statements, parameters, and returned values. We'll discuss the query plan in greater detail in the next section.</p><h3>6.2 Understanding how to read a query plan</h3><p>The <a href="https://www.sqlite.org/eqp.html"><code>EXPLAIN QUERY PLAN</code></a> command is used to determine the strategy or plan that SQLite employs to execute a specific SQL query. In the previous section, we looked at a level 4 log that appeared as follows:</p><pre><code><span class="type">CoreData</span>: details: <span class="type">SQLite</span>: <span class="type">EXPLAIN QUERY PLAN SELECT</span> <span class="number">0</span>, t0.<span class="type">Z_PK</span>, t0.<span class="type">Z_OPT</span>, t0.<span class="type">ZID</span>, t0.<span class="type">ZNAME FROM ZXXX</span> t0 <span class="type">WHERE</span> t0.<span class="type">ZID</span> = ?
     <span class="number">2 0 0</span> <span class="type">SCAN TABLE ZXXX AS</span> t0
</code></pre><p>In this log, the first line is straightforward and represents the SQLite statement. However, the second line contains additional information that might be more difficult to understand. The <code>2 0 0</code> represents identifiers such as node id and parent id, which are used internally. These aren't particularly important, so we can skip over them. The <code>SCAN</code> signifies a full table scan, in other words, no index was used in the current search.</p><p>For reference, when various types of indexes are used to retrieve data, the result of the <code>EXPLAIN QUERY PLAN</code> command will appear as follows:</p><pre><code>-- <span class="type">Index</span> applied
 <span class="number">3 0 0</span> <span class="type">SEARCH</span> t0 <span class="type">USING INDEX Z_XXX_byIDIndex</span> (<span class="type">ZID</span>=?)

-- <span class="type">Covering Index</span> applied
<span class="number">0 0 0</span> <span class="type">SCAN TABLE ZXXX AS</span> t0 <span class="type">USING COVERING INDEX Z_XXX_byIDIndex</span>
</code></pre><p>This way, we can determine which index is actually being used in a fetch request, which is incredibly useful. The query plan can contain valuable information beyond just the use of indexes. You can explore its other uses in the future.</p><h3>6.3 Utilizing Instruments</h3><p>Instruments is a powerful profiling and performance analysis tool provided by Apple. Although it's not directly related to the topic of debugging SQLite, it's worth mentioning. Instruments integrates a default template for Core Data, which we can use:</p><img src="/images/exploring_best_practices_for_core_data_from_sqlite_perspective/6-2.png" alt="6-2"/><p>You might argue that the "Fetch Duration" shown in the screenshot includes not just the SQLite fetch duration but also other parts of the entire Core Data stack. You're absolutely right. However, we can still glean valuable information from the Instruments results. For instance, you can compare the frequency of fetch and save operations, which can assist in designing entities and indexes more effectively.</p><h2>Finally</h2><p>In short, exploring best practices for Core Data from a SQLite perspective can help us understand what's happening behind the scenes. This can be incredibly useful when creating high-performing, scalable, and reliable applications.</p><p>Additionally, monitoring and analyzing performance using tools like the <code>SQLDebug</code> launch argument and Instruments when necessary can help us identify bottlenecks and optimize implementations.</p><p>The content covered in this post is just the tip of the iceberg. There's so much more to explore.</p></div></article><div class="flex justify-between text-xl mt-16"><div class="flex gap-2 w-5/12 self-center"><div class="self-center">←</div><a href="/posts/publish-theme-palette" class="font-medium text-lg underline underline-offset-4 text-xl">为 Publish 打造一款全新的主题</a></div></div><div class="giscus mt-20"></div></div></div><footer class="flex flex-col text-sm font-light mt-auto text-zinc-500 dark:text-zinc-400"><p class="text-center mt-16">Copyright © 2014-2025 Ckitakishi</p><p class="text-center mt-1">Powered by <a href="https://github.com/johnsundell/publish" class="link-underline">Publish</a> &amp; <a href="https://github.com/Ckitakishi/PaletteTheme" class="link-underline">Palette</a></p><div class="grid grid-cols-8 w-full h-[8px] mt-6"><div class="bg-[#ab4642]"></div><div class="bg-[#dc9656]"></div><div class="bg-[#f7ca88]"></div><div class="bg-[#a1b56c]"></div><div class="bg-[#86c1b9]"></div><div class="bg-[#7cafc2]"></div><div class="bg-[#ba8baf]"></div><div class="bg-[#a16946]"></div></div></footer></div><script src="https://giscus.app/client.js"
        data-repo="Ckitakishi/Ckitakishi.github.io"
        data-repo-id="MDEwOlJlcG9zaXRvcnkxNTU4Njk1OQ=="
        data-category="General"
        data-category-id="DIC_kwDOAO3Wj84CBSR7"
        data-mapping="title"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="top"
        data-theme="preferred_color_scheme"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script></body></html>